{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e681c261-9f4a-4874-af47-c03464109f40",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To download index for checkpoints run following in the terminal: \n",
    "    wget https://storage.googleapis.com/vit_models/augreg/index.csv\n",
    "\n",
    "Link to useful colab and github page: \"How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers\"\n",
    "    https://colab.research.google.com/github/google-research/vision_transformer/blob/main/vit_jax_augreg.ipynb\n",
    "    https://github.com/google-research/vision_transformer?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb88a3bf-fb3a-4dce-bd85-9d66e3a34a4c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import torch, timm\n",
    "from  torchvision.transforms import InterpolationMode\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.datasets as datasets\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b2e88d-a74f-49f3-9ff9-6bc76dfe0e70",
   "metadata": {},
   "source": [
    "## Exploring checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eddc076-5c08-4880-bdf7-818eb7a56967",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/index.csv')\n",
    "\n",
    "# all columns of index.csv dataframe\n",
    "index_cols = list(df.columns)\n",
    "\n",
    "# list of all models in the vit family\n",
    "model_types = df.name.unique()\n",
    "\n",
    "# best checkpoint filenames based on pre-train results\n",
    "best_pretrains = set(\n",
    "    df.query('ds==\"i21k\"')\n",
    "    .groupby('name')\n",
    "    .apply(lambda df: df.sort_values('final_val').iloc[-1], include_groups=False)\n",
    "    .filename\n",
    ")\n",
    "# Select all finetunes from these models.\n",
    "best_finetunes = df.loc[df.filename.apply(lambda filename: filename in best_pretrains)]\n",
    "\n",
    "# all adapted datasets\n",
    "adapt_datasets = best_finetunes.adapt_ds.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35a8756-4440-451d-9173-aad9fb9eb1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets   :  ['imagenet2012' 'cifar100' 'resisc45' 'oxford_iiit_pet' 'kitti']\n",
      "Model types:  ['Ti/16' 'S/32' 'B/16' 'L/16' 'R50+L/32' 'R26+S/32' 'S/16' 'B/32'\n",
      " 'R+Ti/16' 'B/8']\n",
      "Index cols :  ['name', 'ds', 'epochs', 'lr', 'aug', 'wd', 'do', 'sd', 'best_val', 'final_val', 'final_test', 'adapt_ds', 'adapt_lr', 'adapt_steps', 'adapt_resolution', 'adapt_final_val', 'adapt_final_test', 'params', 'infer_samples_per_sec', 'filename', 'adapt_filename']\n"
     ]
    }
   ],
   "source": [
    "print('Datasets   : ', adapt_datasets)\n",
    "print('Model types: ', model_types)\n",
    "print('Index cols : ', index_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29f5de49-ab1b-4b29-a8bb-3fa677e64dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def cmp_models(datasets, models_list):\n",
    "    data = {'models': models_list}\n",
    "    for ds in datasets:\n",
    "        info = [\n",
    "            best_finetunes.query(f'name==\"{m}\" and adapt_ds==\"{ds}\"')\n",
    "            .sort_values('adapt_final_val') # I'm not sure whether we should sort by validation result or test result\n",
    "            .iloc[-1] for m in models_list  # but original colab uses validation result\n",
    "        ]\n",
    "        data[f'{ds}-res'] = [int(i.adapt_resolution) for i in info] \n",
    "        data[f'{ds}-val'] = [round(float(i.adapt_final_val), 5) for i in info] \n",
    "        data[f'{ds}-test'] = [round(float(i.adapt_final_test), 5) for i in info] \n",
    "    return pd.DataFrame(data=data)\n",
    "\n",
    "def get_best_model(adapt_ds, model_type):\n",
    "    out = (\n",
    "        best_finetunes.query(f'name==\"{model_type}\" and adapt_ds==\"{adapt_ds}\"')\n",
    "        .sort_values('adapt_final_val').iloc[-1].adapt_filename\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62d5013f-3e52-480e-ae0a-36bd9a591fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>imagenet2012-res</th>\n",
       "      <th>imagenet2012-val</th>\n",
       "      <th>imagenet2012-test</th>\n",
       "      <th>cifar100-res</th>\n",
       "      <th>cifar100-val</th>\n",
       "      <th>cifar100-test</th>\n",
       "      <th>resisc45-res</th>\n",
       "      <th>resisc45-val</th>\n",
       "      <th>resisc45-test</th>\n",
       "      <th>oxford_iiit_pet-res</th>\n",
       "      <th>oxford_iiit_pet-val</th>\n",
       "      <th>oxford_iiit_pet-test</th>\n",
       "      <th>kitti-res</th>\n",
       "      <th>kitti-val</th>\n",
       "      <th>kitti-test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B/16</td>\n",
       "      <td>384</td>\n",
       "      <td>0.89432</td>\n",
       "      <td>0.85486</td>\n",
       "      <td>224</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.9408</td>\n",
       "      <td>384</td>\n",
       "      <td>0.97730</td>\n",
       "      <td>0.97508</td>\n",
       "      <td>384</td>\n",
       "      <td>0.98370</td>\n",
       "      <td>0.94711</td>\n",
       "      <td>224</td>\n",
       "      <td>0.86525</td>\n",
       "      <td>0.81294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S/16</td>\n",
       "      <td>384</td>\n",
       "      <td>0.87082</td>\n",
       "      <td>0.83728</td>\n",
       "      <td>224</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.9206</td>\n",
       "      <td>384</td>\n",
       "      <td>0.97222</td>\n",
       "      <td>0.96556</td>\n",
       "      <td>384</td>\n",
       "      <td>0.96739</td>\n",
       "      <td>0.93430</td>\n",
       "      <td>384</td>\n",
       "      <td>0.85714</td>\n",
       "      <td>0.83475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ti/16</td>\n",
       "      <td>384</td>\n",
       "      <td>0.81993</td>\n",
       "      <td>0.78220</td>\n",
       "      <td>224</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.8801</td>\n",
       "      <td>384</td>\n",
       "      <td>0.96698</td>\n",
       "      <td>0.96143</td>\n",
       "      <td>384</td>\n",
       "      <td>0.95380</td>\n",
       "      <td>0.91142</td>\n",
       "      <td>384</td>\n",
       "      <td>0.85106</td>\n",
       "      <td>0.83122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  models  imagenet2012-res  imagenet2012-val  imagenet2012-test  cifar100-res  \\\n",
       "0   B/16               384           0.89432            0.85486           224   \n",
       "1   S/16               384           0.87082            0.83728           224   \n",
       "2  Ti/16               384           0.81993            0.78220           224   \n",
       "\n",
       "   cifar100-val  cifar100-test  resisc45-res  resisc45-val  resisc45-test  \\\n",
       "0         0.940         0.9408           384       0.97730        0.97508   \n",
       "1         0.922         0.9206           384       0.97222        0.96556   \n",
       "2         0.888         0.8801           384       0.96698        0.96143   \n",
       "\n",
       "   oxford_iiit_pet-res  oxford_iiit_pet-val  oxford_iiit_pet-test  kitti-res  \\\n",
       "0                  384              0.98370               0.94711        224   \n",
       "1                  384              0.96739               0.93430        384   \n",
       "2                  384              0.95380               0.91142        384   \n",
       "\n",
       "   kitti-val  kitti-test  \n",
       "0    0.86525     0.81294  \n",
       "1    0.85714     0.83475  \n",
       "2    0.85106     0.83122  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp_models(adapt_datasets, ['B/16', 'S/16', 'Ti/16'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909c2e6-f23c-4196-bfe5-5d44579ff6b3",
   "metadata": {},
   "source": [
    "## Loading model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff3c3283-761b-40d4-bfb3-aa9d1592b0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() else (\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"cpu\"\n",
    "))\n",
    "\n",
    "sm = torch.nn.Softmax(dim=1)\n",
    "\n",
    "timm_modelnames = {\n",
    "    'Ti/16-224': 'vit_tiny_patch16_224',\n",
    "    'Ti/16-384': 'vit_tiny_patch16_384', \n",
    "    'S/16-224': 'vit_small_patch16_224', \n",
    "    'S/16-384': 'vit_small_patch16_384',\n",
    "    'B/16-224': 'vit_base_patch16_224', \n",
    "    'B/16-384': 'vit_base_patch16_384'\n",
    "}\n",
    "\n",
    "def load_model_and_dataset(adapt_ds, model_type, batch_size):\n",
    "    model_to_load = get_best_model(adapt_ds, model_type)\n",
    "    # sample output: Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--cifar100-steps_10k-lr_0.003-res_224\n",
    "    res = int(model_to_load.split('_')[-1])\n",
    "\n",
    "    # load dataset\n",
    "    ds_transform = v2.Compose([\n",
    "        v2.ToImage(), \n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Resize((res, res)),\n",
    "        v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        # TODO: just some magic numbers for now, I need to find exact numbers that were used\n",
    "        # but these are good enough\n",
    "    ])\n",
    "    \n",
    "    # TODO: generalize dataset loading, works only with cifar100 now\n",
    "    dataset = datasets.CIFAR100('data/', train=False, transform=ds_transform, download=True)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    model = timm.create_model(timm_modelnames[f'{model_type}-{res}'], num_classes=len(dataset.classes))\n",
    "\n",
    "    # downloading a checkpoint automatically\n",
    "    # may show an error, but still downloads the checkpoint\n",
    "    if not tf.io.gfile.exists(f'data/{model_to_load}.npz'):\n",
    "        tf.io.gfile.copy(f'gs://vit_models/augreg/{model_to_load}.npz', f'data/{model_to_load}.npz')\n",
    "\n",
    "    timm.models.load_checkpoint(model, f'data/{model_to_load}.npz')\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model, dataset, dataloader\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "model, dataset, dataloader = load_model_and_dataset('cifar100', 'Ti/16', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d022416-8df9-412d-b6ac-0c04b070065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 313/313 [00:48<00:00,  6.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8811, device='mps:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test():\n",
    "    with torch.no_grad():\n",
    "        acc, correct = 0, 0\n",
    "        for features, labels in tqdm(iter(dataloader)):\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            clf = sm(model(features)).argmax(1)\n",
    "            correct += (clf == labels).sum()\n",
    "    \n",
    "    acc = correct / len(dataset)\n",
    "    return acc\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
