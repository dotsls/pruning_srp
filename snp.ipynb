{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c95aca3",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3691760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and environment setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch, timm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, WeightedRandomSampler, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "_ = torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afef2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common variables: device\n",
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() else (\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"cpu\"\n",
    "))\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a61d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def cmp_arrays(a, b):\n",
    "    if torch._is_all_true(a == b):\n",
    "        print('IDENTICAL')\n",
    "        return True\n",
    "    else:\n",
    "        for ats, at in zip(['1e-8', '1e-6', '1e-4'],[1e-8, 1e-6, 1e-4]): \n",
    "            if torch.allclose(a, b, atol=at):\n",
    "                print(f'CLOSE ENOUGH (atol < {ats})')\n",
    "                return True\n",
    "        print(f'abs distance: {torch.dist(a, b, p=1).item()}')\n",
    "        return False\n",
    "    \n",
    "def test_correctness(A, B, compare_fn, args=[], kwargs={}):\n",
    "        a = A(*args, **kwargs)\n",
    "        b = B(*args, **kwargs)\n",
    "        compare_fn(a, b)\n",
    "\n",
    "def test_speed(A, B, n, args=[], kwargs={}):\n",
    "    for _ in tqdm(range(n[0])):\n",
    "        A(*args, **kwargs)\n",
    "    for _ in tqdm(range(n[1])):\n",
    "        B(*args, **kwargs)\n",
    "\n",
    "def get_random_sample(dataset):\n",
    "    i = np.random.randint(len(dataset))\n",
    "    return dataset[i][0].to(device).unsqueeze(0)\n",
    "\n",
    "def count_classes(ds, indices):\n",
    "    targets = ds.dataset.targets\n",
    "    classes = torch.tensor(targets)[indices]\n",
    "    counts = torch.zeros((100,))\n",
    "    for i in range(100):\n",
    "        counts[i] = (classes == i).sum()\n",
    "    return counts\n",
    "\n",
    "def get_balanced_indices(labels, subset_size):\n",
    "    \"\"\"\n",
    "        labels: list of labels of data samples\n",
    "        subset_size: factor by which to reduce dataset\n",
    "    \"\"\"\n",
    "    labels = torch.tensor(labels, dtype=torch.int32)\n",
    "    num_classes = torch.unique(labels).numel()\n",
    "\n",
    "    indices = [torch.nonzero(labels==i).flatten() for i in range(num_classes)]\n",
    "\n",
    "    numel = int(labels.numel() * subset_size)\n",
    "    per_class = torch.full((num_classes,), int(numel / num_classes), dtype=torch.int32)\n",
    "    remainder = int(numel - int(numel / num_classes)*num_classes)\n",
    "    per_class[:remainder] += 1\n",
    "\n",
    "    per_class_indices = []\n",
    "    for i in range(num_classes):\n",
    "        p = torch.randperm(indices[i].numel())\n",
    "        per_class_indices.append(indices[i][p[:per_class[i]]])\n",
    "\n",
    "    p = torch.randperm(numel)\n",
    "    balanced = list(per_class_indices[0])\n",
    "    for i in range(1, num_classes):\n",
    "        balanced = balanced + list(per_class_indices[i])\n",
    "    balanced = torch.tensor(balanced, dtype=torch.int32)[p]\n",
    "    return list(balanced)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_model(model, dataloader):\n",
    "    sm = torch.nn.Softmax(dim=1)\n",
    "    acc, correct = 0, 0\n",
    "    for features, labels in tqdm(iter(dataloader)):\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        clf = sm(model(features)).argmax(1)\n",
    "        correct += (clf == labels).sum()\n",
    "    acc = correct / len(dataloader.dataset)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8de79c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model_timm, load_dataset\n",
    "def load_model_timm(model_type, dataset_name, verbose=False, top10_idx=-1):\n",
    "    \"\"\" \n",
    "    model   types: B/16, S/16 or Ti/16\n",
    "    dataset names: cifar100 or oxford-iiit-pet\n",
    "    top10_idx    : int [1, 10]\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    index = pd.read_csv('models/index.csv')\n",
    "    pretrains = set(\n",
    "        index.query('ds==\"i21k\"').groupby('name').apply(\n",
    "        lambda df: df.sort_values('final_val').iloc[-1], \n",
    "        include_groups=False).filename\n",
    "    )\n",
    "    finetunes = index.loc[index.filename.apply(lambda name: name in pretrains)]\n",
    "    checkpoint = (\n",
    "        finetunes.query(f'name==\"{model_type}\" and adapt_ds==\"{dataset_name}\"')\n",
    "        .sort_values('adapt_final_val').iloc[-10].adapt_filename\n",
    "    ) # Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--cifar100-steps_10k-lr_0.003-res_224\n",
    "    if verbose: print(f\"Loaded checkpoint: {checkpoint}\")\n",
    "    \n",
    "    timm_modelnames = {\n",
    "        'Ti/16-224': 'vit_tiny_patch16_224',\n",
    "        'Ti/16-384': 'vit_tiny_patch16_384',\n",
    "        'S/16-224': 'vit_small_patch16_224',\n",
    "        'S/16-384': 'vit_small_patch16_384',\n",
    "        'B/16-224': 'vit_base_patch16_224',\n",
    "        'B/16-384': 'vit_base_patch16_384'\n",
    "    }\n",
    "    num_classes = 100 if dataset_name == 'cifar100' else 37\n",
    "    res = int(checkpoint.split('_')[-1])\n",
    "    model = timm.create_model(timm_modelnames[f'{model_type}-{res}'], num_classes=num_classes)\n",
    "    \n",
    "    # downloading a checkpoint automatically\n",
    "    # may show an error, but still downloads the checkpoint\n",
    "    from tensorflow.io import gfile # type: ignore\n",
    "    if not gfile.exists(f'models/{checkpoint}.npz'):     \n",
    "        gfile.copy(f'gs://vit_models/augreg/{checkpoint}.npz', f'models/{checkpoint}.npz')\n",
    "    timm.models.load_checkpoint(model, f'models/{checkpoint}.npz')\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad_(False)\n",
    "    return model\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = seed % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def load_dataset(dataset_name, batch_size, model_cfg=None, subset_size = 1., res = (224, 224), train=False, download_dataset=False, do_balanced_subset=False):\n",
    "    \"\"\"\n",
    "    dataset name: cifar100 or oxford-iiit-pet\n",
    "    \"\"\"\n",
    "    dataset = (\n",
    "        datasets.CIFAR100('data/', train=train, download=download_dataset) if dataset_name == 'cifar100' \n",
    "        else datasets.OxfordIIITPet('data/', split=('trainval' if train else 'test'))\n",
    "    ) \n",
    "    if model_cfg is None:\n",
    "        m, s = [0.5]*3, [0.5]*3\n",
    "    else:\n",
    "        m, s = model_cfg['mean'], model_cfg['std']\n",
    "        res = model_cfg['input_size'][-2:]\n",
    "    dataset.transform = v2.Compose([\n",
    "            v2.ToImage(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean=m, std=s),\n",
    "            v2.Resize(res),\n",
    "    ])\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    if subset_size < 1.0:\n",
    "        n = len(dataset)\n",
    "        n_small = int(subset_size * n)\n",
    "        dataset, _ = random_split(dataset, [n_small, n - n_small], generator=g)\n",
    "        if do_balanced_subset:\n",
    "            balanced_indices = get_balanced_indices(dataset.dataset.targets, subset_size)\n",
    "            dataset.indices = balanced_indices\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)\n",
    "    return dataset, dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd627ea",
   "metadata": {},
   "source": [
    "## work-in-progress code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99f929e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance scoring functions\n",
    "def svd_score_reference(q, k):\n",
    "    \"\"\"q, k shape (batch, head, sequence, dimension)\"\"\"\n",
    "    U, S, Vt = torch.linalg.svd((q @ k.mT).cpu().double())\n",
    "    U, S, Vt = U.to(ref := q), S.to(ref), Vt.to(ref)\n",
    "    \n",
    "    U  =  U.unsqueeze(2).transpose(2, -1)\n",
    "    Vt = Vt.unsqueeze(2).transpose(2, -2)\n",
    "    S  =  S[..., None, None]\n",
    "    svd_maps = ((U * S) @ Vt).flatten(start_dim=-2)\n",
    "\n",
    "    q = q.unsqueeze(2).transpose(2, -1)\n",
    "    k = k.unsqueeze(2).permute(0, 1, 4, 2, 3)\n",
    "    att_maps = (q @ k).flatten(start_dim=-2)\n",
    "\n",
    "    F.normalize(att_maps, dim=-1, out=att_maps)\n",
    "    F.normalize(svd_maps, dim=-1, out=svd_maps)\n",
    "    scores = torch.einsum('bhdm,bhnm->bhdn', att_maps, svd_maps)\n",
    "    torch.abs(scores, out=scores)\n",
    "    return scores.sum(-1)\n",
    "\n",
    "def svd_score(q, k):\n",
    "    \"\"\"q, k shape (batch, head, sequence, dimension)\"\"\"\n",
    "    _, RQ = torch.linalg.qr(q.cpu(), mode='r')\n",
    "    _, RK = torch.linalg.qr(k.cpu(), mode='r')\n",
    "    Ug, S, Vhg = torch.linalg.svd(RQ @ RK.mT, full_matrices=False)\n",
    "    RQ, RK = RQ.to(ref := q), RK.to(ref)\n",
    "    Uhg, Vhg = Ug.mT.to(ref), Vhg.to(ref)    \n",
    "\n",
    "    F.normalize(RQ, dim=2, out=RQ)\n",
    "    F.normalize(RK, dim=2, out=RK)\n",
    "    A, B = Uhg @ RQ, Vhg @ RK\n",
    "    torch.multiply(A, B, out=A)\n",
    "    torch.abs(A, out=A)\n",
    "    return A.sum(-2)\n",
    "\n",
    "\n",
    "def similarity_score_reference(x):\n",
    "    B, _, D = x.shape\n",
    "    score = torch.ones((B, D)) * D\n",
    "    F.normalize(x, dim=1, out=x)\n",
    "    for (d1, d2) in np.ndindex(D, D):\n",
    "        score[:, d1] -= abs((x[:, :, d1] * x[:, :, d2]).sum(dim=1))\n",
    "    return score\n",
    "\n",
    "def similarity_score(x):\n",
    "    \"\"\"input shape (B, N, D) - batch, sequence len, embedding dimension\"\"\"\n",
    "    x = F.normalize(x, dim=1)\n",
    "    score = torch.einsum('bnd,bnt->bdt', x, x)\n",
    "    torch.abs(score, out=score)\n",
    "    score = x.shape[-1] - score.sum(dim=-1) \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ce70181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.1 -0.2  0.5 -0.1]\n",
      "  [ 3.4  1.8 -0.3  0.1]]]\n",
      "[0.8 0.6 0.9 0.5]\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.randn((1, 2, 4))\n",
    "print(a1.numpy())\n",
    "# print(torch.outer(a1[0,0], a1[0,0]))\n",
    "sc = similarity_score(a1).squeeze()\n",
    "print(sc.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d74d7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention block with split qk & v matrices, convert_attention_blocks\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, attn):\n",
    "        super().__init__()\n",
    "        self.fused_attn = attn.fused_attn\n",
    "        \n",
    "        self.num_heads = attn.num_heads\n",
    "        self.scale = attn.scale\n",
    "        # qkv.weight.shape: (num_heads * (2*qk_dim + v_dim), emb_dim)\n",
    "        self.qkv = attn.qkv\n",
    "        self.q_norm = attn.q_norm\n",
    "        self.k_norm = attn.k_norm\n",
    "        self.attn_drop = attn.attn_drop\n",
    "        self.proj = attn.proj\n",
    "        self.proj_drop = attn.proj_drop\n",
    "        \n",
    "        # previous attention class assumed \n",
    "        # that all head dims for Q, K, V are the same\n",
    "        # between heads and between Q, K, V\n",
    "        # this attention class doesn't assume\n",
    "        # that head dims are the same between Q, K, V\n",
    "        # but, still, they're the same between heads of Q, K, V\n",
    "        self.qk_dim, self.v_dim = attn.head_dim, attn.head_dim\n",
    "        self.split_dim = [self.num_heads*c for c in [self.qk_dim]*2+[self.v_dim]]\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, N, _ = x.shape\n",
    "        q, k, v = torch.split(self.qkv(x), self.split_dim, dim=-1)\n",
    "        q = q.reshape(B, N, self.num_heads, self.qk_dim).transpose(1, 2)\n",
    "        k = k.reshape(B, N, self.num_heads, self.qk_dim).transpose(1, 2)\n",
    "        v = v.reshape(B, N, self.num_heads, self.v_dim).transpose(1, 2)\n",
    "        q, k = self.q_norm(q), self.k_norm(k)\n",
    "\n",
    "        if self.fused_attn:\n",
    "            x = F.scaled_dot_product_attention(\n",
    "                q, k, v,\n",
    "                dropout_p=self.attn_drop.p if self.training else 0.,\n",
    "            )\n",
    "        else:\n",
    "            q = q * self.scale\n",
    "            attn = q @ k.transpose(-2, -1)\n",
    "            attn = attn.softmax(dim=-1)\n",
    "            attn = self.attn_drop(attn)\n",
    "            x = attn @ v\n",
    "\n",
    "        x = x.transpose(1, 2).reshape(B, N, self.split_dim[-1])\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "def convert_attention_blocks(model):\n",
    "    for i, b in enumerate(model.blocks):\n",
    "        model.blocks[i].attn = Attention(b.attn)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa80bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hooks and hooks management\n",
    "class SNP:\n",
    "    def __init__(self, attn, do_svd_scoring=True, do_sim_scoring=True):\n",
    "        self.num_heads = attn.num_heads\n",
    "        self.qk_dim = attn.qk_dim\n",
    "        self.v_dim = attn.v_dim\n",
    "        self.split_dim = attn.split_dim\n",
    "        self.scale = attn.scale\n",
    "        self.do_svd_scoring = do_svd_scoring\n",
    "        self.do_sim_scoring = do_sim_scoring\n",
    "        self.svd_scores = 0\n",
    "        self.sim_scores = 0\n",
    "\n",
    "    def __call__(self, module, inp, out):\n",
    "        B, N = out.shape[:2]\n",
    "        q, k, v = torch.split(out, self.split_dim, dim=-1)\n",
    "        q = q.view(B, N, self.num_heads, self.qk_dim).transpose(1, 2)\n",
    "        k = k.view(B, N, self.num_heads, self.qk_dim).transpose(1, 2)\n",
    "        if self.do_svd_scoring:\n",
    "            self.svd_scores = svd_score(q, k)\n",
    "        if self.do_sim_scoring:\n",
    "            self.sim_scores = similarity_score(v).view(B, self.num_heads, self.v_dim)\n",
    "\n",
    "class MLP_SNP:\n",
    "    def __init__(self, module, do_scoring=True):\n",
    "        self.out_features = module.out_features\n",
    "        self.do_scoring = do_scoring\n",
    "        self.sim_scores = 0\n",
    "        \n",
    "    def __call__(self, module, inp, out):\n",
    "        if self.do_scoring:\n",
    "            self.sim_scores = similarity_score(out)\n",
    "\n",
    "def register_hooks(model, scoring_flags):\n",
    "    \"\"\"\n",
    "        scoring_flags: (SVD [QK], cos-sim [V], cos-sim [MLP])\n",
    "    \"\"\"\n",
    "    for b in model.blocks:\n",
    "        snp = SNP(b.attn, *scoring_flags[:2])\n",
    "        b.attn.qkv.register_forward_hook(snp)\n",
    "        mlp = MLP_SNP(b.mlp.fc1, scoring_flags[2])\n",
    "        b.mlp.fc1.register_forward_hook(mlp)\n",
    "    return model\n",
    "\n",
    "def remove_hooks(model):\n",
    "    for b in model.blocks:\n",
    "        b.attn.qkv._forward_hooks.popitem()\n",
    "        b.mlp.fc1._forward_hooks.popitem()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d971e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect_scores, zero_out (weights)\n",
    "def collect_scores(model, dl):\n",
    "    svd_scores, sim_scores, mlp_scores = [], [], []\n",
    "    snp_hooks, mlp_hooks = [], []\n",
    "    for b in model.blocks:\n",
    "        snp_hooks.append(next(iter(b.attn.qkv._forward_hooks.values())))\n",
    "        mlp_hooks.append(next(iter(b.mlp.fc1._forward_hooks.values())))\n",
    "        hook = snp_hooks[-1]\n",
    "        svd_scores.append(torch.zeros((hook.num_heads, hook.qk_dim), device=device))\n",
    "        sim_scores.append(torch.zeros((hook.num_heads, hook.v_dim), device=device))\n",
    "        mlp_scores.append(torch.zeros((mlp_hooks[-1].out_features,), device=device))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, _ in tqdm(dl):\n",
    "            model(features.to(device))\n",
    "            for i, (h1, h2) in enumerate(zip(snp_hooks, mlp_hooks)):\n",
    "                if h1.do_svd_scoring: svd_scores[i] += h1.svd_scores.sum(0)\n",
    "                if h1.do_sim_scoring: sim_scores[i] += h1.sim_scores.sum(0)\n",
    "                if h2.do_scoring: mlp_scores[i] += h2.sim_scores.sum(0)\n",
    "\n",
    "    return svd_scores, sim_scores, mlp_scores\n",
    "\n",
    "def zero_out(model, sparsity, svd_scores, sim_scores, mlp_scores):\n",
    "    svd_list, sim_list, mlp_list = [], [], []\n",
    "    for svd, sim, mlp in zip(svd_scores, sim_scores, mlp_scores):\n",
    "        svd_list.append(svd.sort().indices)\n",
    "        sim_list.append(sim.sort().indices)\n",
    "        mlp_list.append(mlp.sort().indices)\n",
    "\n",
    "    for b, svd, sim, mlp in zip(model.blocks, svd_list, sim_list, mlp_list):\n",
    "        m = b.attn\n",
    "        o = m.qk_dim*m.num_heads\n",
    "        ta, tb = int(m.qk_dim*sparsity[0]), int(m.v_dim*sparsity[1])\n",
    "        for h in range(m.num_heads):\n",
    "            ho, hvo = h * m.qk_dim, h * m.v_dim\n",
    "            \n",
    "            m.qkv.weight[svd[h, :ta]+ho] = 0\n",
    "            m.qkv.weight[svd[h, :ta]+ho+o] = 0\n",
    "            m.qkv.bias[svd[h, :ta]+ho] = 0\n",
    "            m.qkv.bias[svd[h, :ta]+ho+o] = 0\n",
    "\n",
    "            m.qkv.weight[sim[h, :tb]+2*o+hvo] = 0\n",
    "            m.qkv.bias[sim[h, :tb]+hvo] = 0\n",
    "            m.proj.weight[:, sim[h, :tb]+hvo] = 0\n",
    "\n",
    "        \n",
    "        tc = int(b.mlp.fc1.out_features*sparsity[2])\n",
    "        b.mlp.fc1.weight[mlp[:tc]] = 0\n",
    "        b.mlp.fc2.weight[:, mlp[:tc]] = 0\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e002bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruning testing function\n",
    "def full_collect_scores(scoring, modelname, prunelen):\n",
    "    dl = load_dataset('cifar100', 4, subset_size=prunelen)[1]\n",
    "    model = convert_attention_blocks(load_model_timm(modelname, 'cifar100'))\n",
    "    register_hooks(model, scoring)\n",
    "    iscores = collect_scores(model, dl)\n",
    "    remove_hooks(model)\n",
    "\n",
    "    return iscores\n",
    "\n",
    "def test_pruning(scoring, testing, modelname, testlen, prunelen, sparsity_levels, top10_idx=-1):\n",
    "    \"\"\"\n",
    "        scoring: boolean flags (SVD [QK], cos-sim [V], cos-sim [MLP])\n",
    "        testing: boolean flags (Att ,QK, V, MLP, All)\n",
    "        model_type   : ('B/16', 'S/16', 'Ti/16')\n",
    "        testlen, prunelen: float in [0, 1], size of dataset\n",
    "        sparsity_levels: list. which sparsity values to test\n",
    "    \"\"\"\n",
    "    # collecting importance scores\n",
    "    iscores = full_collect_scores(scoring, modelname, prunelen)\n",
    "    model = convert_attention_blocks(load_model_timm(modelname, 'cifar100'))\n",
    "\n",
    "    # variables\n",
    "    colors = ('tab:green', 'tab:red', 'tab:blue', 'tab:purple', 'tab:brown')\n",
    "    testing_flagnames = ('Att', 'SVD', 'Sim', 'MLP', 'All')\n",
    "    sparsity_levels = np.concatenate(([0], sparsity_levels))\n",
    "    n_steps = len(sparsity_levels)\n",
    "    dl  = load_dataset('cifar100', 8, subset_size=testlen)[1]\n",
    "    results = np.full((5, n_steps), float(test_model(model, dl))*100)\n",
    "    sl, z, old_opts = sparsity_levels, [0]*n_steps, np.get_printoptions()\n",
    "    sparsities = [list(zip(*t)) for t in ((sl,sl,z), (sl,z,z), (z,sl,z), (z,z,sl), (sl,sl,sl))]\n",
    "\n",
    "    # evaluating performance after pruning\n",
    "    np.set_printoptions(precision=1, suppress=True, linewidth=100)\n",
    "    for stage in np.flatnonzero(testing):\n",
    "        for step in range(1, n_steps):\n",
    "            zero_out((m := deepcopy(model)), sparsities[stage][step], *iscores)\n",
    "            results[stage, step] = float(test_model(m, dl)) * 100\n",
    "\n",
    "            clear_output(); print(f'Sparsity: {sparsity_levels*100}')\n",
    "            for k, (f, n, r) in enumerate(zip(testing, testing_flagnames, results)):\n",
    "                limit = n_steps if stage>k else step+1\n",
    "                if f and stage>=k: print(f'{n}: {r[:limit]}')\n",
    "    np.set_printoptions(**old_opts)\n",
    "\n",
    "    # plotting results\n",
    "    for stage in np.flatnonzero(testing):\n",
    "        plt.plot(sl, results[stage], color=colors[stage], label=testing_flagnames[stage])\n",
    "    plt.legend(); plt.show()\n",
    "\n",
    "    return iscores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b3c768",
   "metadata": {},
   "source": [
    "## test runs & experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfffeb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "iscores = full_collect_scores([True, False, False], 'Ti/16', .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04a21e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91.408 94.867 87.356 96.691 77.28  82.999 93.851 82.379]\n",
      " [92.465 84.888 93.149 88.187 93.543 85.051 92.371 87.058]\n",
      " [78.349 96.637 95.028 97.292 91.226 70.408 92.024 93.32 ]]\n",
      "[[73.737 74.551 74.874 75.285 77.28  78.359 80.544 81.218]\n",
      " [55.556 63.376 66.182 66.399 68.772 72.144 72.296 72.804]\n",
      " [66.566 69.254 70.408 70.802 71.669 72.173 72.792 75.061]]\n"
     ]
    }
   ],
   "source": [
    "with np.printoptions(precision=3):\n",
    "    print(iscores[0][0][:, :8].cpu().numpy())\n",
    "    print(iscores[0][0].sort().values[:, :8].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a107f377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: [ 0. 10. 30. 50. 70. 90.]\n",
      "Sim: [85.3 26.   2.7  0.5  1.5  1.5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pruning testing setup\n",
    "\"\"\"\n",
    "Expect from paper:\n",
    "SVD: [72.2, 71, 67.5, 58.5, 39, 12]\n",
    "Sim: [72.2, 68, 54  , 28  , 5 , .5]\n",
    "\n",
    "Expect:\n",
    "SVD: [86.8 85.4 81.1 70.3 46.9 14.4]\n",
    "Sim: [86.8 81.8 64.9 33.7  6.    .6]\n",
    "\n",
    "Random:\n",
    "SVD: [86.8 81.  57.7 15.5  1.8]\n",
    "Sim: [86.8 77.7 12.7  4.5  1.5]\n",
    "MLP: [86.8 53.   5.8  1.8  1.3]\n",
    "\n",
    "\n",
    "my {1}:  [85.3 76.5 48.2 35.  16.5]\n",
    "my {16}: [85.3 76.2 47.  34.3 15. ]\n",
    "rng   :  [85.3 82.7 59.2 21.3  5. ]\n",
    "\"\"\"\n",
    "iscores = test_pruning(\n",
    "    [False, True, False], \n",
    "    [False, False, True, False, False], \n",
    "    'Ti/16', .04, .01,\n",
    "    np.linspace(0, .8, 5)+.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b847857",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, N, H, E = 1, 2, 4, 8\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "x = torch.randn((B, N, E))\n",
    "S = torch.randn((B, N, N))\n",
    "S = S.abs() / S.abs().sum(2, keepdim=True)\n",
    "Wv = torch.randn((H, E))\n",
    "Wp = torch.randn((E, H))\n",
    "# V (B, N, H)\n",
    "\n",
    "ims = torch.randperm(H)\n",
    "lim = 2\n",
    "Wv[ims[:lim]] = 0\n",
    "Wp[:, ims[:lim]] = 0\n",
    "\n",
    "V = x @ Wv.mT\n",
    "out = (S @ V) @ Wp.mT\n",
    "print(\n",
    "    'Wv\\n', Wv.numpy(), '\\n\\n', \n",
    "    'V\\n', V.numpy(), '\\n\\n', \n",
    "    'Wp\\n', Wp.mT.numpy(), '\\n\\n', \n",
    "    'Out\\n', out.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e04c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy test of timm model on subset of cifar100\n",
    "\n",
    "# print(test_model(\n",
    "#     convert_attention_blocks(load_model_timm('Ti/16', 'cifar100')),\n",
    "#     load_dataset('cifar100', 8, subset_size=.25)[1]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96282d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test correctness and speed of svd importance scoring algorithm\n",
    "\n",
    "# test_correctness(\n",
    "#     svd_score_reference, svd_score, cmp_arrays,\n",
    "#     (torch.randn(4, 3, 197, 64, device=device), torch.randn(4, 3, 197, 64, device=device))\n",
    "# )\n",
    "\n",
    "# test_speed(\n",
    "#     svd_score_reference, svd_score, [50, 500], \n",
    "#     (torch.randn(4, 3, 197, 64, device=device), torch.randn(4, 3, 197, 64, device=device))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2750f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test correctness and speed of column similarity importance scoring\n",
    "\n",
    "# test_correctness(similarity_score_reference, similarity_score, cmp_arrays, [torch.randn((16,16,16))])\n",
    "\n",
    "# test_speed(similarity_score_reference, similarity_score, [4, 8000], args=[torch.randn(((4, 256, 256)))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
