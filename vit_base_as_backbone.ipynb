{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9c888-8ef8-4ae7-b9b8-2cdc4bb0814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment of using vit-base as backbone and using logistic regression as classification head\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTImageProcessor, ViTModel  # Use ViTModel instead of ViTForImageClassification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time  # For latency measurement\n",
    "from thop import profile  # For FLOPs calculation \n",
    "\n",
    "# === Constants ===\n",
    "MODEL_NAME = \"google/vit-base-patch16-224\"  # Pre-trained ViT model\n",
    "# MODEL_NAME = \"google/vit-base-patch16-224-in21k\"\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "# === Load Model and Processor ===\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(MODEL_NAME, do_rescale=False)\n",
    "model = ViTModel.from_pretrained(MODEL_NAME).eval()  # Use ViTModel for feature extraction\n",
    "\n",
    "# === Prepare Dataset ===\n",
    "transform = Compose([\n",
    "    Resize((IMAGE_SIZE, IMAGE_SIZE)),  # Resize to 224x224\n",
    "    ToTensor()                        # Convert to tensor\n",
    "])\n",
    "\n",
    "# Path to your dataset\n",
    "dataset_root = \"/Users/vladimirzvyozdkin/Studies_Hildesheim/SRP/ViT B16 replication\"  # Specify the path to your data folder\n",
    "\n",
    "# Load Oxford-IIIT Pets dataset\n",
    "train_dataset = OxfordIIITPet(root=dataset_root, split=\"trainval\", transform=transform, download=False)\n",
    "test_dataset = OxfordIIITPet(root=dataset_root, split=\"test\", transform=transform, download=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# === Feature Extraction ===\n",
    "def extract_features(dataloader, model):\n",
    "    features, labels = [], []\n",
    "    with torch.no_grad():  # Disable gradients\n",
    "        for images, targets in tqdm(dataloader, desc=\"Extracting features\"):\n",
    "            inputs = feature_extractor(images, return_tensors=\"pt\")\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "            features.append(embeddings.cpu().numpy())\n",
    "            labels.append(targets.numpy())\n",
    "    return np.vstack(features), np.concatenate(labels)\n",
    "\n",
    "print(\"Extracting features for the training set...\")\n",
    "train_features, train_labels = extract_features(train_loader, model)\n",
    "\n",
    "print(\"Extracting features for the test set...\")\n",
    "test_features, test_labels = extract_features(test_loader, model)\n",
    "\n",
    "# === Train Logistic Regression ===\n",
    "print(\"Training logistic regression...\")\n",
    "clf = LogisticRegression(max_iter=500, verbose=1)\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "# === Evaluate Accuracy ===\n",
    "predictions = clf.predict(test_features)\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy on the test set: {accuracy:.2%}\")\n",
    "\n",
    "# === Measure Latency ===\n",
    "print(\"Measuring latency...\")\n",
    "start_time = time.time()\n",
    "clf.predict(test_features[:1])  # Measure latency for a single prediction\n",
    "end_time = time.time()\n",
    "latency = (end_time - start_time) * 1000  # Convert to milliseconds\n",
    "print(f\"Latency (inference time for one sample): {latency:.2f} ms\")\n",
    "\n",
    "# === Measure FLOPs ===\n",
    "print(\"Calculating FLOPs...\")\n",
    "dummy_input = torch.randn(1, 3, IMAGE_SIZE, IMAGE_SIZE)  # Create a dummy input for FLOPs calculation\n",
    "macs, params = profile(model, inputs=(dummy_input,))\n",
    "flops = macs * 2  # Multiply MACs by 2 to get FLOPs\n",
    "print(f\"FLOPs (floating-point operations): {flops:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa131c9-accd-4f69-b424-b1b323833af8",
   "metadata": {},
   "source": [
    "Copy of the output\n",
    "\n",
    "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']  \n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.  \n",
    "Extracting features for the training set...  \n",
    "Extracting features: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 115/115 [04:17<00:00,  2.24s/it]  \n",
    "Extracting features for the test set...  \n",
    "Extracting features: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 115/115 [04:41<00:00,  2.44s/it]  \n",
    "Training logistic regression...  \n",
    "RUNNING THE L-BFGS-B CODE  \n",
    "\n",
    "           * * *  \n",
    "\n",
    "Machine precision = 2.220D-16  \n",
    " N =        28453     M =           10  \n",
    " This problem is unconstrained.  \n",
    "\n",
    "At X0         0 variables are exactly at the bounds  \n",
    "\n",
    "At iterate    0    f=  3.61092D+00    |proj g|=  1.18076D-01  \n",
    "\n",
    "           * * *  \n",
    "\n",
    "Tit   = total number of iterations  \n",
    "Tnf   = total number of function evaluations  \n",
    "Tnint = total number of segments explored during Cauchy searches  \n",
    "Skip  = number of BFGS updates skipped  \n",
    "Nact  = number of active bounds at final generalized Cauchy point  \n",
    "Projg = norm of the final projected gradient  \n",
    "F     = final function value  \n",
    "\n",
    "           * * *  \n",
    " \n",
    " |N|Tit|Tnf|Tnint|Skip|Nact|Projg|F|\n",
    " |-|---|---|-----|----|----|-----|-|\n",
    "|28453  |   39 |    41   |   1   |  0   |  0   |8.169D-05 |  1.387D-02 | \n",
    "  F =   1.3872503921853369E-002\n",
    "  \n",
    "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL              \n",
    "Accuracy on the test set: 92.72%  \n",
    "Measuring latency...  \n",
    "Latency (inference time for one sample): 0.53 ms  \n",
    "Calculating FLOPs...  \n",
    "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.  \n",
    "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.  \n",
    "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.  \n",
    "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.  \n",
    "FLOPs (floating-point operations): 33,726,904,320.0  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
